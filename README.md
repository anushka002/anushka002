<p align="center">
  <a href="mailto:anushka.satav@asu.edu">
    <img src="https://img.shields.io/badge/Email-anushka.satav@asu.edu-orange?style=flat&logo=gmail" alt="Email" width="220"/>
  </a>
  <a href="https://scholar.google.com/citations?user=Jf1q8iIAAAAJ&hl=en">
    <img src="https://img.shields.io/badge/Google%20Scholar-Profile-green?style=flat&logo=google-scholar" alt="Google Scholar" width="160"/>
  </a>
  <a href="https://www.linkedin.com/in/anushka-satav-g55555/">
    <img src="https://img.shields.io/badge/LinkedIn-Connect-blue?style=flat&logo=linkedin" alt="LinkedIn" width="140"/>
  </a>
  <a href="https://www.instagram.com/_anushka.satav_/?hl=en">
    <img src="https://img.shields.io/badge/Instagram-Follow-violet?style=flat&logo=instagram" alt="Instagram" width="140"/>
  </a>
</p>


# üë©‚Äçüíª Hi, I am Anushka Satav !

Greetings and welcome to my GitHub profile! I am _**Anushka Satav**_, a dedicated robotics enthusiast currently pursuing a Master's in Robotics and Autonomous Systems (Artificial Intelligence) at Arizona State University, Tempe, USA.

My academic and professional journey is driven by a passion for research, design, prototyping, and developing innovative robotic systems. I have a keen interest in the following areas:
- **Artificial Intelligence**
- **Autonomous Robots**
- **Aerial Robots**
- **Underwater Robots**
- **Control Systems**
- **ROS2-based software development**
- **Computer Vision**

---

### üöÄ Skills

| Programming Languages | Robotics & Automation | CAD / FEA Software | AI & Vision |
|-----------------------|------------------------|--------------------|-------------|
| Python, C, C++        | ROS/ROS2, Gazebo, MATLAB | Fusion 360, MSC Apex, Abaqus, Ansys | OpenCV, YOLOv7/8, ML, DL |

---

<details>
<summary><strong>üìö Education</strong></summary>

### üñãÔ∏è Arizona State University, Tempe, AZ  
**Master's in Robotics And Autonomous Systems (Artificial Intelligence)**  
üìÖ _August 2024 - Present_  
- NAMU Scholarship & General Graduate Fellowship Holder (Fall-2024)  
- Semester-I: CSE-571 Artificial Intelligence, RAS-545 Robotic Systems, EGR-501 Linear Algebra  
- Semester-II: RAS-546 Robotic Systems II, RAS-598 Experimentation and Deployment of Robots, RAS-598 Space Robotics and AI

---

### üñãÔ∏è MIT World Peace University, Pune, India  
**Bachelor of Technology in Robotics And Automation**  
üìÖ _August 2019 - August 2023_  
- Silver Medallist, Second Rank Holder  
- Merit Scholarship Holder (2019-2022)  
- Completed Biomechanics Course (National Student Exchange Program at SRM-IST, Kattankulathur)

</details>

---

<details>
<summary>üíº <strong>Experience</strong></summary>

### üñ•Ô∏è Robotics Instructor  
**RoboCHAMPS, Pune, India**  
üìÖ _November 2023 - January 2024_  
- Conducted online hands-on robotics sessions for children aged 7 to 15.  
- Taught programming and robotics using Arduino, ESP32, Microbit and Scratch.

---

### üñ•Ô∏è Robotics Engineering Intern  
**Void Robotics, Florida, USA**  
üìÖ _May 2023 - November 2023_  
- Worked on Arduino libraries, Nav2-navigation stack, and ROS2 development.  
- Gained expertise in Linux, Git, and GitHub operations.

---

### üñ•Ô∏è R&D Intern  
**Hexagon Manufacturing Intelligence Pvt. Ltd, Pune, India**  
üìÖ _February 2023 - September 2023_  
- Conducted advanced simulations using MSC Apex, Nastran, and Dytran.  
- Conducted static, linear, non-linear, and dynamic simulations of 10 different models creating non-linear materials on MSC Apex, Nastran, and Dytran.  
- Built various Custom Tools in MSC Apex to automate model building processes for FEA Analysis with Python.  
- Created a tool automating model creation, constraints, boundary conditions, post-processing for Top Load Analysis on MSC Apex using Nastran for non-linear analysis. Tool reduced model creation time from 20 minutes to less than 2 minutes.

</details>

---
### Publications üìë
<a href="https://scholar.google.com/citations?user=Jf1q8iIAAAAJ&hl=en"><img src="https://img.shields.io/badge/Google%20Scholar-Profile-green?style=flat&logo=google-scholar" alt="Google Scholar" width="160"/></a>

#### 1. **[Overview of Autonomous Vehicles and its Challenges](https://link.springer.com/chapter/10.1007/978-3-031-34648-4_25)**  
   _Techno-Societal 2022: 4th International Conference on Advanced Technologies for Societal Applications_

#### 2. **[A State-of-the-Art Review on Robotics in Waste Sorting: Scope and Challenges](https://link.springer.com/article/10.1007/s12008-023-01320-w)**  
   _International Journal on Interactive Design and Manufacturing (Q2 Journal)_

---
## ü§ñ PROJECT HIGHLIGHTS

### üö§ Autonomous Robotic Boats Series

Explore projects that target real-world aquatic challenges through robotics. These boats use intelligent onboard sensing and navigation for autonomous surface missions, including environmental cleanup.

| **Project** | **Overview** |
|------------|--------------|
| [Towards Robotic Trash Removal with Autonomous Surface Vessels](https://github.com/anushka002/PX4-Robotic-Boat-Lake/tree/master/Project%20Report) | ![image](https://github.com/user-attachments/assets/f15e4087-59df-4dbd-8d58-7bf5a5b2d6a4) <br> **PX4-Based Robotic Boat for Lake Cleanup** <br><br> - Built an autonomous boat platform using PX4 for real-time control <br> - Integrated object detection with mission-level autonomy <br> - Designed to detect and collect floating trash using vision + path planning |

---

### üõ©Ô∏è Parrot Mambo Mini-Drone Series

- This series of mini projects showcases the advanced capabilities of the **Parrot Mambo Minidrone** as a research and learning platform for autonomous aerial robotics. 
- Through the integration of MATLAB and Simulink, each project in this series explores key aspects of drone control‚Äîincluding real-time image processing, color-based object detection, autonomous navigation, and precision landing. 
- From manual keyboard control to fully vision-driven flight, these projects demonstrate how a compact, classroom-grade drone can be transformed into an intelligent autonomous system suitable for real-world prototyping and experimental robotics research.


| **Repository** | **Overview** |
|----------------|--------------|
| <br> **Mini Project 1: Color-Based Object Detection** <br> [View Repository](https://github.com/anushka002/parrot_mambo_series/tree/main/Mini%20Project%201%20Color-Based%20Object%20Detection%20Using%20Parrot%20Mambo%20Drone%20Camera) <br> ![Demo 1](https://github.com/user-attachments/assets/22020549-48d6-4dfe-9658-e8772a628fb7) | <br> - Detected Red, Green, Blue, and Yellow blocks using the drone‚Äôs onboard camera <br> - Implemented color thresholding in Simulink using MATLAB Apps <br> - Built a modular image processing pipeline using MATLAB vision toolbox <br> - First step toward integrating autonomous perception with drone navigation |
| <br> **Mini Project 2: Keyboard Navigation & Color-Based Landing** <br> [View Repository](https://github.com/anushka002/parrot_mambo_series/tree/main/Mini%20Project%202%20Keyboard-Controlled%20Drone%20Navigation%20and%20Color-Based%20Landing%20System) <br> ![gif for github](https://github.com/user-attachments/assets/c598c7f1-8b90-4bd6-8f04-35ae61201e95) | <br> - Enabled manual navigation using keyboard inputs (‚Äòw‚Äô, ‚Äòa‚Äô, ‚Äòs‚Äô, ‚Äòd‚Äô) <br> - Triggered autonomous landing on color detection <br> - Integrated MATLAB image processing logic into the Simulink-based flight controller <br> - Refined descent strategy to ensure smooth landings |
| <br> **Mini Project 3: Autonomous Line Following and Precision Landing** <br> [View Repository](https://github.com/anushka002/parrot_mambo_series/tree/main/Mini%20Project%203%20Autonomous%20Line%20Following%20and%20Precision%20Landing%20of%20a%20Parrot%20Mambo%20Minidrone%20Using%20Simulink) <br> ![final project 3 gif](https://github.com/user-attachments/assets/b153f38f-f477-4c13-b845-d48f4e4db1b1) | <br> - Fully autonomous: drone takes off, tracks R/G/B line, and lands based on symmetry detection <br> - Used MATLAB Simulink and Stateflow for visual servoing, decision-making, and trajectory generation <br> - Centroid-based logic and binary mask analysis guided navigation in real time <br> - Validated with smooth takeoff-to-landing transitions in simulation and real flights |
| <br> **Final Project: Landing Parrot Minidrone on Line-Following AGV** <br> [Project Page Coming Soon](#) <br> ![final project 3 gif](https://github.com/user-attachments/assets/b153f38f-f477-4c13-b845-d48f4e4db1b1) | <br> - Extension of Project 3 toward dynamic landing on a mobile AGV <br> - Will feature UAV-UGV coordination using symmetry tracking and visual cues <br> - Designed to mimic multi-agent coordination in warehouse automation <br> - Currently under development ‚Äì stay tuned! |

---

### üìåFetch Robot Series

The **Fetch Robot Series** is designed to help beginners build a strong foundation in simulating and controlling the Fetch Mobile Manipulator using **ROS Melodic**, **Gazebo** and **MoveIt!**. 
Whether you're just getting started with simulation environments or working toward solving manipulation tasks, this series walks you through the full journey‚Äîfrom setting up the simulation environment to executing motion planning tasks using MoveIt!

These repositories provide practical guidance and solved exercises to familiarize users with robot simulation, kinematics, and motion execution‚Äîcritical skills for research and development in service robotics, warehouse automation, and human-robot interaction.

---

| **Repository** | **Overview** |
|----------------|--------------|
|<br> **Getting Started with Fetch Simulation in ROS Melodic** <br> [ROS-Melodic-Fetch-Robot](https://github.com/anushka002/ROS-Melodic-Fetch-Robot) <br> ![fetch test](https://github.com/user-attachments/assets/310996b0-fad7-472e-a560-11c178b9e83d) |  <br> - Step-by-step setup guide for running Fetch robot simulation in ROS Melodic on Ubuntu 18.04 <br> - Launch files for Gazebo world, Fetch robot URDF, and RViz <br> - Instructions for setting up `fetch_gazebo`, `fetch_moveit_config`, and `move_group_interface` <br> - Helps users build a reproducible and stable simulation workspace |
| <br> **Motion Planning and Control Tasks with Fetch Robot** <br> [fetch-ros-exercise](https://github.com/anushka002/fetch-ros-exercise) <br> ![task3](https://github.com/user-attachments/assets/7fe9f968-504e-42e9-839d-127f21a890f4) | <br> - Series of solved robotics tasks using MoveIt and ROS Melodic <br> - Includes joint state publishing, gripper control, and planning to PoseGoal/JointGoal <br> - Demonstrates how to visualize and execute robot plans in RViz <br> - A practical extension for those who have completed the setup guide |

---

### üê¢ TurtleBot4 ROS 2 Series

The **TurtleBot4 ROS 2 Series** explores autonomous navigation, voice-commanded control, and real-time object detection using TurtleBot4 and ROS 2 Humble. Whether you're working in simulation or on real hardware, these projects offer step-by-step demonstrations of core robotics concepts‚Äîfrom basic launch setups to full autonomy using perception and path planning.

This series is perfect for robotics enthusiasts, university students, or developers diving into ROS 2 and mobile robot systems.

| **Repository** | **Overview** |
|----------------|--------------|
| [TurtleBot4-ROS2-Series](https://github.com/anushka002/TurtleBot4-ROS2-Series) | ![tb4_demo](https://github.com/user-attachments/assets/placeholder-turtlebot4.gif) <br> **Voice-Guided Navigation and Object Detection with YOLOv8 in ROS 2** <br><br> - Launches TurtleBot4 in Gazebo and RViz with integrated TF, laser scan, and navigation stack <br> - Integrates YOLOv8 for real-time object detection <br> - Accepts voice commands to guide the robot across mapped environments <br> - Combines Nav2, `cmd_vel`, and speech recognition pipelines for autonomy |

---

### ü¶æ Robotic Manipulator Series

This series features projects centered around intelligent robotic arms‚Äîfrom academic research to AI-enhanced task execution. These systems explore advanced perception, planning, and manipulation in both industrial and experimental settings.

| **Project** | **Overview** |
|------------|--------------|
| [Maze Solving with MyCobot Pro 600 (M.S. RAS-545)](https://github.com/anushka002/maze_solver_with_cobot_pro) | ![cobot_maze](https://github.com/user-attachments/assets/a13265df-8d03-458d-9584-87480f8a8ca3) <br> **Solving a 4x4 Maze with AI Camera and Digital Twin** <br><br> - Utilized a MyCobot Pro 600 and AI Camera Kit for solving maze paths <br> - Built a digital twin in MATLAB for simulating trajectory planning <br> - Integrated vision-based decision making with robotic arm actuation |
| [Robotic Arm for Waste Sorting (Final Year B.Tech)](https://github.com/anushka002/robotic_arm_waste_sorting/blob/main/README.md) | ![robot arm 4dof](https://github.com/user-attachments/assets/aa40d386-3bbf-42d6-b29a-70a5fb14e499) <br> **4-DOF Arduino-Based Waste Segregation Robot** <br><br> - Designed and built a robotic arm for sorting waste by material type <br> - Used YOLOv7 to classify glass, paper, plastic, and metal items <br> - Focused on sustainable automation and smart recycling |


---

### üìö Other Projects

Explore a curated selection of individual robotics projects that highlight simulation, perception, and control using ROS, MATLAB, and Python. These projects serve as compact demonstrations of specific concepts‚Äîperfect for quick learning or as building blocks for larger applications.

| **Project** | **Overview** |
|-------------|--------------|
| [Digital Twins for Robot Manipulators (MATLAB)](https://github.com/anushka002/manipulator_digital_twins) |  <br> **Simulink-based Digital Twin Modeling of a 2-DOF Robotic Arm** <br><br> - Built real-time digital twin using MATLAB and Simulink <br> - Implemented kinematic modeling and parameter synchronization between physical and virtual twins <br> - Includes comparison plots and simulation validation |
| [Mini Project ‚Äì ROS2 Turtlesim: Catch Them All](https://github.com/anushka002/ros2_rookie_ws) |   <br> **Multi-Agent TurtleBot Task Using ROS2 and Python** <br><br> - Implemented a search and capture game using multiple turtlesim nodes in ROS2 <br> - Uses `rclpy` for control and publishing targets <br> - Reinforces topics like node creation, subscriber/publisher logic, and coordinate tracking |


---

### Certifications üìÑ
- **Udemy:**
  - ROS2 for Beginners (Foxy, Humble - 2024)
  - ROS2 for Beginners Level 2 (TF | URDF | RViz | Gazebo)
- **NPTEL:**
  - Introduction to Robotics
  - Introduction to Internet of Things
- **Coursera:**
  - Python for Everybody
  - Python Data Structure (University of Michigan)
  
---

<div align="center">
  <blockquote style="font-style: italic; font-size: 1.2em;">
    &ldquo;Success is not the key to happiness. Happiness is the key to success. If you love what you are doing, you will be successful.&rdquo;
    <br>
    <span style="font-weight: bold;">‚Äì Albert Schweitzer</span>
  </blockquote>
</div>

---

![Endless Possibilities](https://media.giphy.com/media/PlLanl8Bzcvr14IfjJ/giphy.gif)
![Robot GIF](https://media.giphy.com/media/EBysPyjz3BHVu/giphy.gif)
---

**Interests:** üé® Sketching üéÆ Gaming üì∏ Photography ‚úàÔ∏è Traveling

If interested, check out my page at - <a href="https://www.instagram.com/_anushka.satav_/?hl=en">
    <img src="https://img.shields.io/badge/Instagram-AnushkaSatav-violet?style=flat&logo=instagram" alt="Instagram" width="180"/>
  </a>

---




